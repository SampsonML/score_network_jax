{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "A jax implementation of the diffusion model from \n",
        "the paper \"Improved Techniques for Training Score-Based Generative Models\"\n",
        "https://arxiv.org/abs/2006.09011\n",
        "Code taken primarily from https://github.com/yang-song/score_sde/\n",
        "Modifications by Matt Sampson include:\n",
        "    - Minor updates to use the latest version of flax\n",
        "\"\"\"\n",
        "\n",
        "# temporary fix for flax.optim issue:\n",
        "# https://stackoverflow.com/questions/73488909/attributeerror-module-flax-has-no-attribute-optim\n",
        "#!pip uninstall flax -y\n",
        "#!pip install flax==0.5.1\n",
        "# proper fix here (https://flax.readthedocs.io/en/latest/advanced_topics/optax_update_guide.html)\n",
        "# not yet implemented\n",
        "\n",
        "%matplotlib inline\n",
        "import functools\n",
        "import math\n",
        "import string\n",
        "from typing import Any, Sequence, Optional\n",
        "import flax.linen as nn\n",
        "import jax\n",
        "import jax.nn as jnn\n",
        "import jax.numpy as jnp\n",
        "import jax.nn.initializers as init\n",
        "import matplotlib as mpl\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import flax\n",
        "Path(\"outputs\").mkdir(exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"Common layers for defining score networks.\n",
        "\"\"\"\n",
        "class InstanceNorm2dPlus(nn.Module):\n",
        "  \"\"\"InstanceNorm++ as proposed in the original NCSN paper.\"\"\"\n",
        "  bias: bool = True\n",
        "\n",
        "  @staticmethod\n",
        "  def scale_init(key, shape, dtype=jnp.float32):\n",
        "    normal_init = init.normal(0.02)\n",
        "    return normal_init(key, shape, dtype=dtype) + 1.\n",
        "\n",
        "  @nn.compact\n",
        "  def __call__(self, x):\n",
        "    means = jnp.mean(x, axis=(1, 2))\n",
        "    m = jnp.mean(means, axis=-1, keepdims=True)\n",
        "    v = jnp.var(means, axis=-1, keepdims=True)\n",
        "    means_plus = (means - m) / jnp.sqrt(v + 1e-5)\n",
        "\n",
        "    h = (x - means[:, None, None, :]) / jnp.sqrt(jnp.var(x, axis=(1, 2), keepdims=True) + 1e-5)\n",
        "\n",
        "    h = h + means_plus[:, None, None, :] * self.param('alpha', InstanceNorm2dPlus.scale_init, (1, 1, 1, x.shape[-1]))\n",
        "    h = h * self.param('gamma', InstanceNorm2dPlus.scale_init, (1, 1, 1, x.shape[-1]))\n",
        "    if self.bias:\n",
        "      h = h + self.param('beta', init.zeros, (1, 1, 1, x.shape[-1]))\n",
        "\n",
        "    return h\n",
        "\n",
        "\n",
        "def ncsn_conv1x1(x, out_planes, stride=1, bias=True, dilation=1, init_scale=1.):\n",
        "  \"\"\"1x1 convolution with PyTorch initialization. Same as NCSNv1/v2.\"\"\"\n",
        "  init_scale = 1e-10 if init_scale == 0 else init_scale\n",
        "  kernel_init = jnn.initializers.variance_scaling(1 / 3 * init_scale, 'fan_in',\n",
        "                                                  'uniform')\n",
        "  kernel_shape = (1, 1) + (x.shape[-1], out_planes)\n",
        "  bias_init = lambda key, shape: kernel_init(key, kernel_shape)[0, 0, 0, :]\n",
        "  output = nn.Conv(out_planes, kernel_size=(1, 1),\n",
        "                   strides=(stride, stride), padding='SAME', use_bias=bias,\n",
        "                   kernel_dilation=(dilation, dilation),\n",
        "                   kernel_init=kernel_init,\n",
        "                   bias_init=bias_init)(x)\n",
        "  return output\n",
        "\n",
        "\"\"\" Old version of ncsn_conv3x3 \"\"\"\n",
        "\"\"\"\n",
        "def ncsn_conv3x3(x, out_planes, stride=1, bias=True, dilation=1, init_scale=1.):\n",
        "  # 3x3 convolution with PyTorch initialization. Same as NCSNv1/NCSNv2.\n",
        "  init_scale = 1e-10 if init_scale == 0 else init_scale\n",
        "  kernel_init = jnn.initializers.variance_scaling(1 / 3 * init_scale, 'fan_in',\n",
        "                                                  'uniform')\n",
        "  kernel_shape = (3, 3) + (x.shape[-1], out_planes)\n",
        "  bias_init = lambda key, shape: kernel_init(key, kernel_shape)[0, 0, 0, :]\n",
        "  output = nn.Conv(out_planes,\n",
        "                   kernel_size=(3, 3),\n",
        "                   strides=(stride, stride),\n",
        "                   padding='SAME',\n",
        "                   use_bias=bias,\n",
        "                   kernel_dilation=(dilation, dilation),\n",
        "                   kernel_init=kernel_init,\n",
        "                   bias_init=bias_init)(x)\n",
        "  return output\n",
        "\"\"\"\n",
        "\n",
        "def ncsn_conv3x3(x, out_planes, stride=1, bias=True, dilation=1, init_scale=1.):\n",
        "  \"\"\"3x3 convolution with PyTorch initialization. Same as NCSNv1/NCSNv2.\"\"\"\n",
        "  kernel_init = jnn.initializers.variance_scaling(1 / 3 * init_scale, 'fan_in',\n",
        "                                                  'uniform')\n",
        "  kernel_shape = (3, 3) + (x.shape[-1], out_planes)\n",
        "  #bias_init = lambda key, shape: kernel_init(key, kernel_shape)[0, 0, 0, :]\n",
        "  bias_init = jnn.initializers.zeros\n",
        "  output = nn.Conv(out_planes,\n",
        "                   kernel_size=(3, 3),\n",
        "                   strides=(stride, stride),\n",
        "                   padding='SAME',\n",
        "                   use_bias= bias,\n",
        "                   kernel_dilation=(dilation, dilation),\n",
        "                   kernel_init=kernel_init,\n",
        "                   bias_init=bias_init)(x)\n",
        "  return output\n",
        "\n",
        "# How to call bias_init search this and see - flax outdated thing\n",
        "# Make a github repo for this\n",
        "# Get much more familiar with github\n",
        "# add a requirement.txt to show which versions of modules are needed\n",
        "\n",
        "# ---------------------------------------------------------------- #\n",
        "# Functions below are ported over from the NCSNv1/NCSNv2 codebase: #\n",
        "# https://github.com/ermongroup/ncsn                               #\n",
        "# https://github.com/ermongroup/ncsnv2                             #\n",
        "# ---------------------------------------------------------------- #\n",
        "\n",
        "class CRPBlock(nn.Module):\n",
        "  \"\"\"CRPBlock for RefineNet. Used in NCSNv2.\"\"\"\n",
        "  features: int\n",
        "  n_stages: int\n",
        "  act: Any = nn.relu\n",
        "\n",
        "  @nn.compact\n",
        "  def __call__(self, x):\n",
        "    x = self.act(x)\n",
        "    path = x\n",
        "    for _ in range(self.n_stages):\n",
        "      path = nn.max_pool(\n",
        "        path, window_shape=(5, 5), strides=(1, 1), padding='SAME')\n",
        "      path = ncsn_conv3x3(path, self.features, stride=1, bias=False)\n",
        "      x = path + x\n",
        "    return x\n",
        "\n",
        "\n",
        "class RCUBlock(nn.Module):\n",
        "  \"\"\"RCUBlock for RefineNet. Used in NCSNv2.\"\"\"\n",
        "  features: int\n",
        "  n_blocks: int\n",
        "  n_stages: int\n",
        "  act: Any = nn.relu\n",
        "\n",
        "  @nn.compact\n",
        "  def __call__(self, x):\n",
        "    for _ in range(self.n_blocks):\n",
        "      residual = x\n",
        "      for _ in range(self.n_stages):\n",
        "        x = self.act(x)\n",
        "        x = ncsn_conv3x3(x, self.features, stride=1, bias=False)\n",
        "      x = x + residual\n",
        "\n",
        "    return x\n",
        "\n",
        "class MSFBlock(nn.Module):\n",
        "  \"\"\"MSFBlock for RefineNet. Used in NCSNv2.\"\"\"\n",
        "  shape: Sequence[int]\n",
        "  features: int\n",
        "  interpolation: str = 'bilinear'\n",
        "\n",
        "  @nn.compact\n",
        "  def __call__(self, xs):\n",
        "    sums = jnp.zeros((xs[0].shape[0], *self.shape, self.features))\n",
        "    for i in range(len(xs)):\n",
        "      h = ncsn_conv3x3(xs[i], self.features, stride=1, bias=True)\n",
        "      if self.interpolation == 'bilinear':\n",
        "        h = jax.image.resize(h, (h.shape[0], *self.shape, h.shape[-1]), 'bilinear')\n",
        "      elif self.interpolation == 'nearest_neighbor':\n",
        "        h = jax.image.resize(h, (h.shape[0], *self.shape, h.shape[-1]), 'nearest')\n",
        "      else:\n",
        "        raise ValueError(f'Interpolation {self.interpolation} does not exist!')\n",
        "      sums = sums + h\n",
        "    return sums\n",
        "\n",
        "class RefineBlock(nn.Module):\n",
        "  \"\"\"RefineBlock for building NCSNv2 RefineNet.\"\"\"\n",
        "  output_shape: Sequence[int]\n",
        "  features: int\n",
        "  act: Any = nn.relu\n",
        "  interpolation: str = 'bilinear'\n",
        "  start: bool = False\n",
        "  end: bool = False\n",
        "\n",
        "  @nn.compact\n",
        "  def __call__(self, xs):\n",
        "    rcu_block = functools.partial(RCUBlock, n_blocks=2, n_stages=2, act=self.act)\n",
        "    rcu_block_output = functools.partial(RCUBlock,\n",
        "                                        features=self.features,\n",
        "                                        n_blocks=3 if self.end else 1,\n",
        "                                        n_stages=2,\n",
        "                                        act=self.act)\n",
        "    hs = []\n",
        "    for i in range(len(xs)):\n",
        "      h = rcu_block(features=xs[i].shape[-1])(xs[i])\n",
        "      hs.append(h)\n",
        "\n",
        "    if not self.start:\n",
        "      msf = functools.partial(MSFBlock, features=self.features, interpolation=self.interpolation)\n",
        "      h = msf(shape=self.output_shape)(hs)\n",
        "    else:\n",
        "      h = hs[0]\n",
        "\n",
        "    crp = functools.partial(CRPBlock, features=self.features, n_stages=2, act=self.act)\n",
        "    h = crp()(h)\n",
        "    h = rcu_block_output()(h)\n",
        "    return h\n",
        "\n",
        "class ConvMeanPool(nn.Module):\n",
        "  \"\"\"ConvMeanPool for building the ResNet backbone.\"\"\"\n",
        "  output_dim: int\n",
        "  kernel_size: int = 3\n",
        "  biases: bool = True\n",
        "\n",
        "  @nn.compact\n",
        "  def __call__(self, inputs):\n",
        "    output = nn.Conv(features=self.output_dim,\n",
        "                    kernel_size=(self.kernel_size, self.kernel_size),\n",
        "                    strides=(1, 1),\n",
        "                    padding='SAME',\n",
        "                    use_bias=self.biases)(inputs)\n",
        "    output = sum([\n",
        "      output[:, ::2, ::2, :], output[:, 1::2, ::2, :],\n",
        "      output[:, ::2, 1::2, :], output[:, 1::2, 1::2, :]\n",
        "    ]) / 4.\n",
        "    return output\n",
        "\n",
        "\n",
        "class MeanPoolConv(nn.Module):\n",
        "  \"\"\"MeanPoolConv for building the ResNet backbone.\"\"\"\n",
        "  output_dim: int\n",
        "  kernel_size: int = 3\n",
        "  biases: bool = True\n",
        "\n",
        "  @nn.compact\n",
        "  def __call__(self, inputs):\n",
        "    output = inputs\n",
        "    output = sum([\n",
        "      output[:, ::2, ::2, :], output[:, 1::2, ::2, :],\n",
        "      output[:, ::2, 1::2, :], output[:, 1::2, 1::2, :]\n",
        "    ]) / 4.\n",
        "    output = nn.Conv(\n",
        "      features=self.output_dim,\n",
        "      kernel_size=(self.kernel_size, self.kernel_size),\n",
        "      strides=(1, 1),\n",
        "      padding='SAME',\n",
        "      use_bias=self.biases)(output)\n",
        "    return output\n",
        "\n",
        "\n",
        "class ResidualBlock(nn.Module):\n",
        "  \"\"\"The residual block for defining the ResNet backbone. Used in NCSNv2.\"\"\"\n",
        "  output_dim: int\n",
        "  normalization: Any\n",
        "  resample: Optional[str] = None\n",
        "  act: Any = nn.elu\n",
        "  dilation: int = 1\n",
        "\n",
        "  @nn.compact\n",
        "  def __call__(self, x):\n",
        "    h = self.normalization()(x)\n",
        "    h = self.act(h)\n",
        "    if self.resample == 'down':\n",
        "      h = ncsn_conv3x3(h, h.shape[-1], dilation=self.dilation)\n",
        "      h = self.normalization()(h)\n",
        "      h = self.act(h)\n",
        "      if self.dilation > 1:\n",
        "        h = ncsn_conv3x3(h, self.output_dim, dilation=self.dilation)\n",
        "        shortcut = ncsn_conv3x3(x, self.output_dim, dilation=self.dilation)\n",
        "      else:\n",
        "        h = ConvMeanPool(output_dim=self.output_dim)(h)\n",
        "        shortcut = ConvMeanPool(output_dim=self.output_dim, kernel_size=1)(x)\n",
        "    elif self.resample is None:\n",
        "      if self.dilation > 1:\n",
        "        if self.output_dim == x.shape[-1]:\n",
        "          shortcut = x\n",
        "        else:\n",
        "          shortcut = ncsn_conv3x3(x, self.output_dim, dilation=self.dilation)\n",
        "        h = ncsn_conv3x3(h, self.output_dim, dilation=self.dilation)\n",
        "        h = self.normalization()(h)\n",
        "        h = self.act(h)\n",
        "        h = ncsn_conv3x3(h, self.output_dim, dilation=self.dilation)\n",
        "      else:\n",
        "        if self.output_dim == x.shape[-1]:\n",
        "          shortcut = x\n",
        "        else:\n",
        "          shortcut = ncsn_conv1x1(x, self.output_dim)\n",
        "        h = ncsn_conv3x3(h, self.output_dim)\n",
        "        h = self.normalization()(h)\n",
        "        h = self.act(h)\n",
        "        h = ncsn_conv3x3(h, self.output_dim)\n",
        "\n",
        "    return h + shortcut\n",
        "\n",
        "class ConditionalResidualBlock(nn.Module):\n",
        "  \"\"\"The noise-conditional residual block for building NCSNv1.\"\"\"\n",
        "  output_dim: int\n",
        "  normalization: Any\n",
        "  resample: Optional[str] = None\n",
        "  act: Any = nn.elu\n",
        "  dilation: int = 1\n",
        "\n",
        "  @nn.compact\n",
        "  def __call__(self, x, y):\n",
        "    h = self.normalization()(x, y)\n",
        "    h = self.act(h)\n",
        "    if self.resample == 'down':\n",
        "      h = ncsn_conv3x3(h, h.shape[-1], dilation=self.dilation)\n",
        "      h = self.normalization(h, y)\n",
        "      h = self.act(h)\n",
        "      if self.dilation > 1:\n",
        "        h = ncsn_conv3x3(h, self.output_dim, dilation=self.dilation)\n",
        "        shortcut = ncsn_conv3x3(x, self.output_dim, dilation=self.dilation)\n",
        "      else:\n",
        "        h = ConvMeanPool(output_dim=self.output_dim)(h)\n",
        "        shortcut = ConvMeanPool(output_dim=self.output_dim, kernel_size=1)(x)\n",
        "    elif self.resample is None:\n",
        "      if self.dilation > 1:\n",
        "        if self.output_dim == x.shape[-1]:\n",
        "          shortcut = x\n",
        "        else:\n",
        "          shortcut = ncsn_conv3x3(x, self.output_dim, dilation=self.dilation)\n",
        "        h = ncsn_conv3x3(h, self.output_dim, dilation=self.dilation)\n",
        "        h = self.normalization()(h, y)\n",
        "        h = self.act(h)\n",
        "        h = ncsn_conv3x3(h, self.output_dim, dilation=self.dilation)\n",
        "      else:\n",
        "        if self.output_dim == x.shape[-1]:\n",
        "          shortcut = x\n",
        "        else:\n",
        "          shortcut = ncsn_conv1x1(x, self.output_dim)\n",
        "        h = ncsn_conv3x3(h, self.output_dim)\n",
        "        h = self.normalization()(h, y)\n",
        "        h = self.act(h)\n",
        "        h = ncsn_conv3x3(h, self.output_dim)\n",
        "\n",
        "    return h + shortcut"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "Gba5FAb0tAOt"
      },
      "outputs": [],
      "source": [
        "\"\"\" \n",
        "MATT:\n",
        "Want to build a U-NET in jax which will have 5 layers (to match Song+2020)\n",
        "Need to take into acount the noise scales - ie embedding the noise scale into the model\n",
        "Build this with flax.linen (flax.linen as nn)?\n",
        "\"\"\"\n",
        "# grabbed from https://github.com/yang-song/score_sde/blob/main/models/ncsnv2.py\n",
        "\n",
        "CondResidualBlock = ConditionalResidualBlock\n",
        "conv3x3 = ncsn_conv3x3\n",
        "\n",
        "class NCSNv2(nn.Module):\n",
        "  \"\"\"NCSNv2 model architecture\"\"\"\n",
        "  #config: ml_collections.ConfigDict\n",
        "\n",
        "  @nn.compact\n",
        "  def __call__(self, x, labels, train=True):\n",
        "    \n",
        "    # hard coding configs for now\n",
        "    sigma_begin   = 1                     # noise scale max\n",
        "    sigma_end     = 1e-2                  # noise scale min\n",
        "    num_scales    = 10                     # number of noise scales\n",
        "    sigmas        = jnp.exp(jnp.linspace(jnp.log(sigma_end), \n",
        "                              jnp.log(sigma_begin),num_scales))\n",
        "    im_size       = 32                    # image size\n",
        "    nf            = 128                   # number of filters\n",
        "    act           = nn.elu                # activation function\n",
        "    normalizer    = InstanceNorm2dPlus    # normalization function\n",
        "    interpolation = 'bilinear'            # interpolation method for upsample\n",
        "    \n",
        "    # data already centered\n",
        "    h = x\n",
        "    \n",
        "    # Begin the U-Net\n",
        "    h = conv3x3(h, nf, stride=1, bias=True)\n",
        "\n",
        "    # ResNet backbone\n",
        "    h = ResidualBlock(nf, resample=None, act=act, normalization=normalizer)(h)\n",
        "    layer1 = ResidualBlock(nf, resample=None, act=act, normalization=normalizer)(h)\n",
        "    h = ResidualBlock(2 * nf, resample='down', act=act, normalization=normalizer)(layer1)\n",
        "    layer2 = ResidualBlock(2 * nf, resample=None, act=act, normalization=normalizer)(h)\n",
        "    h = ResidualBlock(2 * nf,\n",
        "                      resample='down',\n",
        "                      act=act,\n",
        "                      normalization=normalizer,\n",
        "                      dilation=2)(layer2)\n",
        "    layer3 = ResidualBlock(2 * nf, resample=None, act=act, normalization=normalizer, dilation=2)(h)\n",
        "    h = ResidualBlock(2 * nf,\n",
        "                      resample='down',\n",
        "                      act=act,\n",
        "                      normalization=normalizer,\n",
        "                      dilation=4)(layer3)\n",
        "    layer4 = ResidualBlock(2 * nf, resample=None, act=act, normalization=normalizer, dilation=4)(h)\n",
        "    # U-Net with RefineBlocks\n",
        "    ref1 = RefineBlock(layer4.shape[1:3],\n",
        "                       2 * nf,\n",
        "                      act=act,\n",
        "                      interpolation=interpolation,\n",
        "                      start=True)([layer4])\n",
        "    ref2 = RefineBlock(layer3.shape[1:3],\n",
        "                       2 * nf,\n",
        "                      interpolation=interpolation,\n",
        "                      act=act)([layer3, ref1])\n",
        "    ref3 = RefineBlock(layer2.shape[1:3],\n",
        "                       2 * nf,\n",
        "                      interpolation=interpolation,\n",
        "                      act=act)([layer2, ref2])\n",
        "    ref4 = RefineBlock(layer1.shape[1:3],\n",
        "                      nf,\n",
        "                      interpolation=interpolation,\n",
        "                      act=act,\n",
        "                      end=True)([layer1, ref3])\n",
        "\n",
        "    h = normalizer()(ref4)\n",
        "    h = act(h)\n",
        "    h = conv3x3(h, x.shape[-1])\n",
        "\n",
        "    # normlising the output\n",
        "    used_sigmas = sigmas[labels].reshape(\n",
        "        (x.shape[0], *([1] * len(x.shape[1:]))))\n",
        "    return h / used_sigmas\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "The loss function for a noise dependent score model from Song+2020\n",
        "\"\"\"\n",
        "def anneal_dsm_score_estimation(model, samples, labels, sigmas, key, anneal_power=2.):\n",
        "    sigmas = sigmas[..., None]\n",
        "    noise = jax.random.normal(key, samples.shape)\n",
        "    perturbed_samples = samples + noise * sigmas\n",
        "    target = -noise / sigmas\n",
        "    scores = model(perturbed_samples, labels)\n",
        "    loss = 1 / 2. * ((scores - target) ** 2).sum(axis=-1) * sigmas.squeeze() ** anneal_power\n",
        "    return loss.mean(axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "MtP7sqAOtAOt",
        "outputId": "d6d3874a-d434-4f51-8e45-cec448828d84"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD9CAYAAAB6KwG7AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAANTUlEQVR4nO3dfYhl9X3H8fd3Zx9mEHV8WEEtcWNNsj4gFaqIbZX+IdVgW1wTCDUsBqlNDQih0NYUk/aPCgpNKzSbksQS25jUf7Y2pRihUBJjm8al4hO6ZKNWataHdSe6rtlZZ/fbP+6ZeDPeMzO798ydh+/7BZez5/c999zfnt3P/O4959zfRGYiae1bt9wdkDQahl0qwrBLRRh2qQjDLhVh2KUi1o/iRSJiE3Bps7oXODKK15UKGQPObP78WGZOz92gs7BHxMeA64GDwP9m5l/2lS8FHunqtSTN6zeA789t7ORtfERcDdwBbM/MW4ALI+K2LvYtqRtdfWa/C/hWZs6+Pf9H4C8iYqJZ39vR60ha2MC8DR32iDgHuAR4qq/5CWASuKpZ9zO6NDoD89bFyH5hs9zX1zbVLLd2sH9JHegi7JPNcn9f2+yZwBM62L+kDnQR9jea5aa+ttnP6lNIWhG6CPueZnl6X9vmZvlsB/uX1IGhw56ZPwZ28d5NMwAX0Htb/+iw+5fUja4uvd0JbOtbvwn4fGYe7mj/kobUyR10mfnPEXFmRPw9cBj4r8z8Uhf7ltSNzm6XzcwdXe1LUvf81ptUhGGXijDsUhGGXSrCsEtFGHapCMMuFWHYpSIMu1SEYZeKMOxSEYZdKsKwS0UYdqkIwy4VYdilIgy7VIRhl4ow7FIRhl0qwrBLRRh2qQjDLhVh2KUiDLtUhGGXijDsUhGGXSrCsEtFdPZbXDU6EdFay8wR9kSriSO7VIRhl4ow7FIRhl0qwrBLRRh2qQgvva1C811eW79+8D/pzMzMUnVHq4Qju1SEYZeKMOxSEYZdKsKwS0V4Nn4V2rBhQ2tt06ZNA9vffvvtpeqOVglHdqkIwy4VYdilIgy7VIRhl4ow7FIRXnpbhU444YTW2rp1g39+j4+Ptz7n0KFDQ/dJK58ju1SEYZeKMOxSEYZdKsKwS0UYdqmIRV96i4gzgD8BJjLz1jm1zwCXAgF8LzPv7bSXBW3cuLG11vbNNmifg26+y2tjY2OttSNHjrTWtLosKuwRMQ78OvA7wKNzajcD12XmtdH7JWSPRMS+zPyXznsr6bgt6m18Zh7KzJ3AD/vbI2IDcCdwX7NdAvcDd3XcT0lDOtbP7O/OWb8COAN4qq/tCeAjEbF1mI5J6tawJ+gubJb7+tqmmqVhl1aQYcM+2Sz397VNN8v2G7gljdywYX+jWfafHp5ollNIWjGG/dbbnmZ5OjA7o+HmZvnskPsubb5JJScmJlpr77zzzsD28847r/U5+/fvb6299dZbx1XTyjPsyP5d4BV619hnXQA8nZkvDLlvSR061rCPNQ8AMnMGuBu4ASAi1gGfBD7XVQcldWPRYY+IG4ErgSsj4vf6Sn8D7I6IHcDXgL/NzH/ttJeShrboz+yZeT+9G2bmtifwhS47Jal7fhFGKsKwS0U44eQKdfDgwdbazMxMa23btm0D288999zW5+zevbu19txzz7XWXn755dba1JS3Waw0juxSEYZdKsKwS0UYdqkIwy4VYdilIrz0tkK1/c42gFNPPbW11vZ74C6//PLW52zevLm11rtBcrD5JrFsu3R4+PDh1udoaTmyS0UYdqkIwy4VYdilIgy7VIRn41eoo0ePttb27t3bWhsfHx/YfvHFF7c+5+yzz26tvfrqq621119/vbX2yiuvDGz3bPzycWSXijDsUhGGXSrCsEtFGHapCMMuFeGltzXm8ccfH9jedikM4LLLLmutPfnkk621xx57rLW2cePG1pqWhyO7VIRhl4ow7FIRhl0qwrBLRRh2qQgvva0xu3btGtj+jW98o/U5Bw4caK2ddtpprbW2+e4A3n333daalocju1SEYZeKMOxSEYZdKsKwS0UYdqkIL72tMdPT0wPbH3roodbn7Nu3r7U2OTnZWjvppJNaa2NjY601LQ9HdqkIwy4VYdilIgy7VIRhl4ow7FIRXnorYs+ePa21k08+ubU23+W1559/vrU23++q0/JwZJeKMOxSEYZdKsKwS0UYdqkIz8aLZ555prU2MTHRWlu/3v8+q4kju1SEYZeKMOxSEYZdKsKwS0UYdqmIRV07iYizgB3AbwKvAXdn5lf76lcBnwamgEPAH2fmTPfd1VJom7cOYOPGja21zGytzcwM/ucfHx9vfc6hQ4daaxreYkf2rwL/DdwK7AW+EhEfB4iIi4D7gD/IzFvphf3uJeirpCHEfD+dASJiK3BOZj7crE8Au4FdmbktInYCr2Xmp5v6+cBTwJbM/L+mbQvwwpL9LTSUiGitnXjiia21devax4rDhw8PbJ/vq6+O7J35YGa+OLdxMSP787NBB8jMnwE/AKYjYhy4ll64Z+0GZoDrhuqupE4tGPbMHPQj+kzgAeBcYBzY17f9UeBNYGtHfZTUgWM+Gx8RHwKmM/NBYLJp3j9ns2mg/Zd3Sxq5Ywp79D7c3Q5sb5reaJab5mw6Qe/MvKQV4li/tvRZYEdm/qRZfwk4DJw+u0FErAdOAZ7tpIdacvOdpJ3vpNl8J/bavhHnSbjls+iRPSK2A49n5q45z/82cGlf24eBo8B3OumhpE4s9qaam4GLgNci4hpgA/BR4Mv0rqk/EBEbm5N5NwH3ZObepemypOOxmOvsnwLuBea+Z3smMy9qtrkBuJ7eiboDwB3NWfnZfWzB6+yr0nx30B3P2/iDBw8O3SctaOB19gXD3gXDvnoZ9lXpuG+qkbQGGHapCGcM1Lza7nGH+d/ie4lt5XFkl4ow7FIRhl0qwrBLRRh2qQjDLhXhpTcdtyNHjrTWRnFnpo6NI7tUhGGXijDsUhGGXSrCsEtFeDZex22+X/jg2fiVx5FdKsKwS0UYdqkIwy4VYdilIgy7VISX3nTcvLy2ujiyS0UYdqkIwy4VYdilIgy7VIRhl4ow7FIRhl0qwrBLRRh2qQjDLhVh2KUiDLtUhGGXijDsUhGGXSrCsEtFGHapCMMuFWHYpSIMu1SEYZeKMOxSEYZdKsKwS0UYdqkIwy4VYdilIgy7VIRhl4ow7FIRhl0qwrBLRSwq7BFxakTsjIgDEfF0RFw5p/6xiLg/Ir4SEX+2NF2VNIzFjuxfAL4GXAO8BeyMiA0AEXE1cAewPTNvAS6MiNuWorOShpCZ8z6ATcAH+tYvBY4CpzTr/wP8aV/9WmAKmOhr2wKkDx8+RvLYMijLC47smTmdmS/1NW0AHsjMqYg4B7gEeKqv/gQwCVy10L4ljc4xnaCLiNOAzwF/1DRd2Cz39W021Sy3Dtc1SV1adNgj4nzgS/Q+tz8SEafTG8EB9vdtOt0sT+iig5K6seiwZ+azmfkJ4ArgLOAW4I2mvKlv04lmOYWkFeOYr7Nn5g+Bf6IX+D1N8+l9m2xuls8O1zVJXTrem2p+CjyRmT8GdtE7Qz/rAnpv6x8drmuSurRg2CPipIi4KSImm/UPAL8C/EOzyZ3Atr6n3AR8PjMPd9pTSUOJ5jp4+wYRHwIeBk4G/gN4EbgrM1/v2+ZW4FeBw8DuzPzrOfvYArzQZccltfpgZr44t3HBsHfBsEsjNTDso/oizNiIXkdSS95GFfYzR/Q6klry5ldcpSJG9Zl9E+9dntsLHFnyF5VqGeO9Ef2xzJyeu8FIwi5p+fk2XirCsEtFGHapiGUJe/U56yLijIj4q4jYMaD2mYj4ekTcFxE3L0f/RiUizoqIByPizYj4UUT8/pz6VRHxrYjYERFfjIj1y9XXUVnS+R4Xmpaq6wdwNb3ZbMaa9W8Ct426H8v1AMbpfZfgR8DX59RuBh5q/hzA94HfXe4+L+Gx+DfgduBG4Hv0plT6eFO7iN6t2Sc163cCX1zuPo/gmNwDfBT4NeA/6U0Ms6GpDZWd5fjLLDhnXYUHcH9/2OlN9/Uq8Im+tj8Enlvuvi7R338r8Ft96xPAS8DOZn0n8Hd99fOBGeCXlrvvS3hMhp7vcb7HSN/GO2fdL3h3zvoVwBm8/9h8JCLW4hRfz2fmw7Mrmfkz4AfAdESM0/uP3H8sdtML+3Uj7eUI5RLP9zjqz+zOWdeu1LHJwV+BPhN4ADiX3sedfX3bHwXeZA0ei0GWYr7HUYd9slk6Z937TTbLksem+Sr1dGY+yOBjAb3jUeFYLMl8j6MOu3PWtSt7bCIi6J2o2940DToW0Dsea/pYwNLN9zjqsDtnXbvKx+azwI7M/Emz/hK9iVB+fiyay26nsPaPxc9lx/M9jjTs6Zx18/ku8ArvPzZPZ+aanfgjIrYDj2fmrr7mdcC3+cVj8WF6Z6a/M8LurQQ/paP5HpfjphrnrOsZo2+SgcycAe4GbgCIiHXAJ+mdpFmTmpuGLgE2RcQ1EfHbEfFl4JfpHYtrI2Jjs/lNwD2ZuXd5erv0lnq+x2X51ttCc9atdRFxI71/OIDbM/ObTXsAf07v7dk48O+ztbUmIj4F3Evv5qF+z2TmRc02NwDX0xu9DgB3NGfl16Qu5nucd//LEXZJo+cXYaQiDLtUhGGXijDsUhGGXSrCsEtFGHapCMMuFWHYpSL+Hy6SZeNMmvnYAAAAAElFTkSuQmCC",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/mattsampson/homebrew/lib/python3.9/site-packages/flax/optim/base.py:49: DeprecationWarning: Use `optax` instead of `flax.optim`. Refer to the update guide https://flax.readthedocs.io/en/latest/howtos/optax_update_guide.html for detailed instructions.\n",
            "  warnings.warn(\n",
            "  0%|          | 0/1001 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "Argument 'NCSNv2()' of type <class '__main__.NCSNv2'> is not a valid JAX type.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m/Users/mattsampson/Princeton/research/score_network_jax/diffusion_jax_HSC.ipynb Cell 5\u001b[0m in \u001b[0;36m<cell line: 72>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mattsampson/Princeton/research/score_network_jax/diffusion_jax_HSC.ipynb#W5sZmlsZQ%3D%3D?line=75'>76</a>\u001b[0m idx \u001b[39m=\u001b[39m jax\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mrandint(key_seq, (\u001b[39m1\u001b[39m,), minval\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, maxval\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(dataset), dtype\u001b[39m=\u001b[39mjnp\u001b[39m.\u001b[39mint32)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mattsampson/Princeton/research/score_network_jax/diffusion_jax_HSC.ipynb#W5sZmlsZQ%3D%3D?line=76'>77</a>\u001b[0m labels \u001b[39m=\u001b[39m jax\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mrandint(key_seq, (\u001b[39mlen\u001b[39m(dataset[idx]),), minval\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, maxval\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(sigmas), dtype\u001b[39m=\u001b[39mjnp\u001b[39m.\u001b[39mint32)\u001b[39m# size for 32 by 32\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/mattsampson/Princeton/research/score_network_jax/diffusion_jax_HSC.ipynb#W5sZmlsZQ%3D%3D?line=77'>78</a>\u001b[0m model, optimizer, key_seq \u001b[39m=\u001b[39m train_step(model, optimizer, \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mattsampson/Princeton/research/score_network_jax/diffusion_jax_HSC.ipynb#W5sZmlsZQ%3D%3D?line=78'>79</a>\u001b[0m                             key_seq, dataset[idx], labels, sigmas[labels])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mattsampson/Princeton/research/score_network_jax/diffusion_jax_HSC.ipynb#W5sZmlsZQ%3D%3D?line=80'>81</a>\u001b[0m \u001b[39mif\u001b[39;00m ((t \u001b[39m%\u001b[39m (steps \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m \u001b[39m5\u001b[39m)) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mattsampson/Princeton/research/score_network_jax/diffusion_jax_HSC.ipynb#W5sZmlsZQ%3D%3D?line=81'>82</a>\u001b[0m     labels \u001b[39m=\u001b[39m jax\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mrandint(key_seq, (\u001b[39mlen\u001b[39m(dataset[\u001b[39m0\u001b[39m]),), minval\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, maxval\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(sigmas), dtype\u001b[39m=\u001b[39mjnp\u001b[39m.\u001b[39mint32)\n",
            "    \u001b[0;31m[... skipping hidden 2 frame]\u001b[0m\n",
            "File \u001b[0;32m~/homebrew/lib/python3.9/site-packages/jax/_src/api.py:3080\u001b[0m, in \u001b[0;36m_check_arg\u001b[0;34m(arg)\u001b[0m\n\u001b[1;32m   3078\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_check_arg\u001b[39m(arg):\n\u001b[1;32m   3079\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39misinstance\u001b[39m(arg, core\u001b[39m.\u001b[39mTracer) \u001b[39mor\u001b[39;00m _valid_jaxtype(arg)):\n\u001b[0;32m-> 3080\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mArgument \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00marg\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m of type \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(arg)\u001b[39m}\u001b[39;00m\u001b[39m is not a valid JAX type.\u001b[39m\u001b[39m\"\u001b[39m)\n",
            "\u001b[0;31mTypeError\u001b[0m: Argument 'NCSNv2()' of type <class '__main__.NCSNv2'> is not a valid JAX type."
          ]
        }
      ],
      "source": [
        "\"\"\" \n",
        "The training of the NCSNv2 model. Here define the training\n",
        "parameters and initialise the model. Train on a small scale \n",
        "for testing before moving to the full scale on GPU HPC.\n",
        "\"\"\"\n",
        "# ----------- #\n",
        "# model setup #\n",
        "# ----------- #\n",
        "\n",
        "# load in data  \n",
        "box_size = 31\n",
        "dataname = 'sources_box' + str(box_size) + '.npy'     \n",
        "dataset = np.load(dataname)\n",
        "\n",
        "# perform zero-padding of the data to get desired dimensions\n",
        "data_padded_31 = []\n",
        "for i in range(len(dataset)):\n",
        "    data_padded_tmp = np.pad(dataset[i], ((0,1),(0,1)), 'constant')\n",
        "    data_padded_31.append(data_padded_tmp)\n",
        "dataset = np.array( data_padded_31 )\n",
        "\n",
        "# convert dataset to jax array\n",
        "data_jax = jnp.array(dataset)\n",
        "\n",
        "# define noise levels \n",
        "sigma_begin = 1\n",
        "sigma_end   = 0.01\n",
        "num_scales  = 10\n",
        "sigmas      = jnp.exp(jnp.linspace(jnp.log(sigma_end), \n",
        "                        jnp.log(sigma_begin),num_scales))\n",
        "\n",
        "# score model params\n",
        "n_epochs    = 50                                    # number of epochs\n",
        "steps       = 1_000                                 # number of steps per epoch\n",
        "batch_size  = 32                                    # batch size\n",
        "lr          = 1e-4                                  # learning rate\n",
        "rng         = jax.random.PRNGKey(1992)              # random seed\n",
        "input_shape = (jax.local_device_count(), 32, 32, 1) # size 32 by 32 one channel\n",
        "label_shape = input_shape[:1]\n",
        "fake_input  = jnp.zeros(input_shape)\n",
        "fake_label  = jnp.zeros(label_shape, dtype=jnp.int32)\n",
        "params_rng, dropout_rng = jax.random.split(rng)\n",
        "model = NCSNv2()\n",
        "#model = model_def()\n",
        "variables = model.init({'params': params_rng}, fake_input, fake_label)\n",
        "# Variables is a `flax.FrozenDict`. It is immutable and respects functional programming\n",
        "init_model_state, initial_params = variables.pop('params')\n",
        "optimizer = flax.optim.Adam(learning_rate=lr,\n",
        "                            beta1 = 0.9,\n",
        "                            eps = 1e-8).create(initial_params)  # create optimizer\n",
        "\n",
        "# ------------- #\n",
        "# training loop #\n",
        "# ------------- #\n",
        "@jax.jit\n",
        "def train_step(model, optimizer, rng, samples, labels, sigmas):\n",
        "    rng   = jax.random.PRNGKey(rng) # random number random seed\n",
        "    grads = jax.grad(anneal_dsm_score_estimation)(model, samples, labels, sigmas, rng)\n",
        "    model = optimizer.update(grads, model)\n",
        "    return model, optimizer, rng\n",
        "\n",
        "key_seq = jax.random.PRNGKey(0)\n",
        "for t in tqdm(range(steps + 1)):\n",
        "\n",
        "    #idx = np.random.randint(0, len(dataset))\n",
        "    #labels = np.random.randint(0, len(sigmas), size=len(dataset[idx])) # size for 32 by 32\n",
        "    idx = jax.random.randint(key_seq, (1,), minval=0, maxval=len(data_jax), dtype=jnp.int32)\n",
        "    labels = jax.random.randint(key_seq, (len(data_jax[idx]),), minval=0, maxval=len(sigmas), dtype=jnp.int32)\n",
        "    model, optimizer, key_seq = train_step(model, optimizer, \n",
        "                                key_seq, data_jax[idx], labels, sigmas[labels])\n",
        "\n",
        "    if ((t % (steps // 5)) == 0):\n",
        "        labels = jax.random.randint(key_seq, (len(data_jax[0]),), minval=0, maxval=len(sigmas), dtype=jnp.int32)\n",
        "        print(anneal_dsm_score_estimation(model, data_jax[0], labels, sigmas[labels], key_seq))\n",
        "# -------------------- #\n",
        "# end of training loop #       \n",
        "# -------------------- #"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "CallCompactUnboundModuleError",
          "evalue": "Can't call compact methods on unbound modules (https://flax.readthedocs.io/en/latest/flax.errors.html#flax.errors.CallCompactUnboundModuleError)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mCallCompactUnboundModuleError\u001b[0m             Traceback (most recent call last)",
            "\u001b[1;32m/Users/mattsampson/Princeton/research/HSC_galaxies/diffusion_modelling/diffusion_jax_HSC.ipynb Cell 9\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mattsampson/Princeton/research/HSC_galaxies/diffusion_modelling/diffusion_jax_HSC.ipynb#X16sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m galaxy \u001b[39m=\u001b[39m dataset[\u001b[39m1992\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mattsampson/Princeton/research/HSC_galaxies/diffusion_modelling/diffusion_jax_HSC.ipynb#X16sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m labels \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mrandint(\u001b[39m0\u001b[39m, \u001b[39mlen\u001b[39m(sigmas), (gaussian_noise\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m],))\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/mattsampson/Princeton/research/HSC_galaxies/diffusion_modelling/diffusion_jax_HSC.ipynb#X16sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m scores \u001b[39m=\u001b[39m model(gaussian_noise, labels)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mattsampson/Princeton/research/HSC_galaxies/diffusion_modelling/diffusion_jax_HSC.ipynb#X16sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m scores2 \u001b[39m=\u001b[39m model(galaxy, labels)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mattsampson/Princeton/research/HSC_galaxies/diffusion_modelling/diffusion_jax_HSC.ipynb#X16sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m fig , ax \u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39msubplots(\u001b[39m1\u001b[39m,\u001b[39m2\u001b[39m,figsize\u001b[39m=\u001b[39m(\u001b[39m16\u001b[39m, \u001b[39m5.5\u001b[39m), facecolor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mblack\u001b[39m\u001b[39m'\u001b[39m,dpi \u001b[39m=\u001b[39m \u001b[39m70\u001b[39m)\n",
            "File \u001b[0;32m~/homebrew/lib/python3.9/site-packages/flax/linen/transforms.py:1228\u001b[0m, in \u001b[0;36mnamed_call.<locals>.wrapped_fn\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1226\u001b[0m module_name \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\n\u001b[1;32m   1227\u001b[0m full_name \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mmodule_name\u001b[39m}\u001b[39;00m\u001b[39m{\u001b[39;00mmethod_suffix\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[0;32m-> 1228\u001b[0m \u001b[39mreturn\u001b[39;00m jax\u001b[39m.\u001b[39;49mnamed_call(class_fn, name\u001b[39m=\u001b[39;49mfull_name)(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[0;32m~/homebrew/Cellar/python@3.9/3.9.13_1/Frameworks/Python.framework/Versions/3.9/lib/python3.9/contextlib.py:79\u001b[0m, in \u001b[0;36mContextDecorator.__call__.<locals>.inner\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[39m@wraps\u001b[39m(func)\n\u001b[1;32m     77\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minner\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds):\n\u001b[1;32m     78\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_recreate_cm():\n\u001b[0;32m---> 79\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n",
            "File \u001b[0;32m~/homebrew/lib/python3.9/site-packages/flax/linen/module.py:350\u001b[0m, in \u001b[0;36mwrap_method_once.<locals>.wrapped_module_method\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[39mif\u001b[39;00m args \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(args[\u001b[39m0\u001b[39m], Module):\n\u001b[1;32m    349\u001b[0m   \u001b[39mself\u001b[39m, args \u001b[39m=\u001b[39m args[\u001b[39m0\u001b[39m], args[\u001b[39m1\u001b[39m:]\n\u001b[0;32m--> 350\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_wrapped_method(fun, args, kwargs)\n\u001b[1;32m    351\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    352\u001b[0m   \u001b[39mreturn\u001b[39;00m fun(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
            "File \u001b[0;32m~/homebrew/lib/python3.9/site-packages/flax/linen/module.py:643\u001b[0m, in \u001b[0;36mModule._call_wrapped_method\u001b[0;34m(self, fun, args, kwargs)\u001b[0m\n\u001b[1;32m    641\u001b[0m \u001b[39mif\u001b[39;00m is_compact_method:\n\u001b[1;32m    642\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscope \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 643\u001b[0m     \u001b[39mraise\u001b[39;00m errors\u001b[39m.\u001b[39mCallCompactUnboundModuleError()\n\u001b[1;32m    644\u001b[0m   is_recurrent \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state\u001b[39m.\u001b[39min_compact_method\n\u001b[1;32m    645\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state\u001b[39m.\u001b[39min_compact_method \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
            "\u001b[0;31mCallCompactUnboundModuleError\u001b[0m: Can't call compact methods on unbound modules (https://flax.readthedocs.io/en/latest/flax.errors.html#flax.errors.CallCompactUnboundModuleError)"
          ]
        }
      ],
      "source": [
        "# ------------------------ #\n",
        "# testing score estimation #\n",
        "# ------------------------ #\n",
        "gaussian_noise = jax.random.normal(rng, shape=(32,32))\n",
        "galaxy = dataset[1992]\n",
        "labels = np.random.randint(0, len(sigmas), (gaussian_noise.shape[0],))\n",
        "scores = model(gaussian_noise, labels)\n",
        "scores2 = model(galaxy, labels)\n",
        "fig , ax = plt.subplots(1,2,figsize=(16, 5.5), facecolor='black',dpi = 70)\n",
        "plt.subplots_adjust(wspace=0.01)\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(scores, cmap='plasma')\n",
        "#plt.colorbar()\n",
        "plt.title('Gaussian Noise',fontsize=28,pad=15)\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(scores2, cmap='plasma')\n",
        "cbar = plt.colorbar()\n",
        "cbar.set_label(r'$\\nabla_x log \\ p(\\mathbf{\\tilde{x}})$', rotation=270, fontsize = 20,labelpad= 25)\n",
        "plt.title('Galaxy',fontsize=28,pad=15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iXfpd5tptAOt",
        "outputId": "72601a87-db35-4a44-91d6-64744b9fc1fb"
      },
      "outputs": [],
      "source": [
        "# ------------------------- #\n",
        "# langevin dynamic sampling #\n",
        "# ------------------------- #\n",
        "# TODO: port to jax\n",
        "\n",
        "def anneal_Langevin_dynamics(x_mod, scorenet, sigmas, n_steps_each=100, step_lr=0.000008,\n",
        "                             final_only=False, verbose=False, denoise=True):\n",
        "    images = []\n",
        "    scores  = []\n",
        "\n",
        "    for c, sigma in enumerate(sigmas):\n",
        "        labels = torch.ones(x_mod.shape[0], device=x_mod.device) * c\n",
        "        labels = labels.long()\n",
        "        step_size = step_lr * (sigma / sigmas[-1]) ** 2\n",
        "        step_size_cpu = step_size.to('cpu') \n",
        "        for s in range(n_steps_each):\n",
        "            grad = scorenet(x_mod, labels)\n",
        "            scores.append(grad.to('cpu'))\n",
        "            noise = torch.randn_like(x_mod)\n",
        "            grad_norm = torch.norm(grad.view(grad.shape[0], -1), dim=-1).mean()\n",
        "            noise_norm = torch.norm(noise.view(noise.shape[0], -1), dim=-1).mean()\n",
        "            x_mod = x_mod + step_size_cpu * grad + noise * np.sqrt(step_size_cpu * 2)\n",
        "\n",
        "            if not final_only:\n",
        "                images.append(x_mod.to('cpu'))\n",
        "\n",
        "    if denoise:\n",
        "        last_noise = (len(sigmas) - 1) * torch.ones(x_mod.shape[0], device=x_mod.device)\n",
        "        last_noise = last_noise.long()\n",
        "        x_mod = x_mod + sigmas[-1] ** 2 * scorenet(x_mod, last_noise)\n",
        "        images.append(x_mod.to('cpu'))\n",
        "\n",
        "    return images, scores"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "latex_envs": {
      "LaTeX_envs_menu_present": true,
      "autoclose": false,
      "autocomplete": true,
      "bibliofile": "biblio.bib",
      "cite_by": "apalike",
      "current_citInitial": 1,
      "eqLabelWithNumbers": true,
      "eqNumInitial": 1,
      "hotkeys": {
        "equation": "Ctrl-E",
        "itemize": "Ctrl-I"
      },
      "labels_anchors": false,
      "latex_user_defs": false,
      "report_style_numbering": false,
      "user_envs_cfg": false
    },
    "vscode": {
      "interpreter": {
        "hash": "3bc68688a3ed8a5ce6018ce4ac9bdddfcbacccfa8757535ca0e210f8a40fad74"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
